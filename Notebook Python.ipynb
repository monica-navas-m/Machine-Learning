{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "310cddea",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING GROUP PROJECT \n",
    "\n",
    "### Group Members: Helena Krumm (55577), Marouan Kamoun (53833), Mila Gardini (54742), Monica Navas (54577), Yassine Hafi (54466) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955e9e61",
   "metadata": {},
   "source": [
    "## **Index**\n",
    "* [Overview and Business Applications](#intro)\n",
    "* [Dataset Information (Metadata)](#meta)\n",
    "* [Import libraries](#libraries)\n",
    "* [Reading and Data Cleaning](#clean)\n",
    "* [Exploratory Data Analysis](#eda)\n",
    "* [Model 1 : Decision Tree ](#model1)\n",
    "* [Model 2 : Logistic Regression ](#model2)\n",
    "* [Model 3 : ANN ](#model3)\n",
    "* [Model 4 : Random Forests ](#model4)\n",
    "* [Model 5 : XG Boosting ](#model5)\n",
    "* [Model 6 : Ensemble Model ](#model5)\n",
    "* [Model Comparison](#compare)\n",
    "* [Best Model Selection and Improvement](#best)\n",
    "* [Conclusion](#conclusion)\n",
    "* [Sources](#sources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aa4690",
   "metadata": {},
   "source": [
    "<a name=\"intro\"></a>\n",
    "## Overview \n",
    "\n",
    "The cover type is the plant growth characteristic of an area. Forests are one of the most critical ecosystems on our planet, and they provide a range of benefits to both people and the environment. However, forests around the world are facing numerous threats, including deforestation, invasive species, and climate change impacts. To address these issues, we need a better understanding of the state of the forest ecosystem and the factors that influence forest health. This is where environmental monitoring comes in.\n",
    "\n",
    "Our are of interest is Colorado, US, and we aim to provide an academica research that will serve as environmental monitoring, which is a critical aspect of sustainable forest management, as it allows us to understand the state of a forest ecosystem and identify potential threats to its health. By analyzing the cartographic variables and forest cover type data in this project, we gain insights into the relationship between different environmental factors and forest health. \n",
    "\n",
    "The \"Covertype\" dataset contains information about forest cover types, data originally derived from the US Forest Service (USFS) and the US Geological Survey (USGS), which can be used to inform various **environmental monitoring and management applications.** The study area includes four wilderness areas located in the Roosevelt National Forest (1.5 million acres) of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices. \n",
    "\n",
    "Our scientific research aims to lay the foundation to serve as a benchmark for managerial choices in forest management. Using machine learning models, we can analyze changes in forest cover over time and identify areas that are undergoing rapid change or that are particularly vulnerable to environmental threats. "
   ]
  },
  {
   "attachments": {
    "5faed93e90341.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "id": "1f671f49",
   "metadata": {},
   "source": [
    "<a name=\"meta\"></a>\n",
    "## Business Application\n",
    "\n",
    "Our environmental monitoring services can ideally benefit a range of clients, but since the area under study, is not affected by woodland exploitation, this research is directed to the government or conservation organizations for the purpose of better management and planning over time. \n",
    "This area has great potential, and our research can be combined in the future with research on local wildlife and animal movement, so that the Colorado state government can properly document and administer the forested space (whether there is the presence of particularly flammable shrubs and where, cleaning the understory in order to prevent fires).\n",
    "\n",
    "### Why does this research have a feasible impact?\n",
    "Specifically talking about wildfires, there is a growing trend, 2020 witnessed the highest number of wildfires ever recorded in the history of the state of Colorado.\n",
    "<img src=\"attachment:5faed93e90341.webp\" alt=\"Burned Colorado acres\" width=\"500\" height=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969cefdd",
   "metadata": {},
   "source": [
    "In October 2020, nearly 442,000 acres in north-central Colorado and southern Wyoming have been affected by this seasonâ€™s wildfires, according to the Rocky Mountain Coordination Center. Approximately 3.000 firefighters and support personnel were involved. \n",
    "\n",
    "<img src=\"attachment:areaswithwildfires.png\" alt=\"Wildfires in Colorado 2020\" width=\"300\" height=\"450\">\n",
    "\n",
    "With this research, we provide valuable insights for informed decision-making, benefiting governments and conservation organizations. They can make better choices regarding forest management, wildfire prevention, conservation planning, and climate change adaptation in the Roosevelt National Forest and its surroundings. Additionally, this can be bought and licenced to serve as environmental consulting services from interested organizations operating in or near forested areas in Colorado (and Wyoming). It would help them comply with wildfire prevention regulations, develop emergency response plans, and ensure adherence to environmental laws and guidelines.\n",
    "Expenditures can be minimized on their operations, promoting sustainable practices and safeguarding the long-term sustainability of Colorado's forests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0500cf4e",
   "metadata": {},
   "source": [
    "<a name=\"meta\"></a>\n",
    "## Dataset informations\n",
    "\n",
    "Number of instances (observations):  581,012\n",
    "\n",
    "Number of Attributes:\t12 measures, but 54 columns of data (10 quantitative variables, 4 binary wilderness areas and 40 binary soil type variables).\n",
    "\n",
    "\n",
    "1.\tAttribute information:\n",
    "\n",
    "Given is the attribute name, attribute type, the measurement unit and a brief description.  The forest cover type is the classification problem. \n",
    "\n",
    "    Name                                     Data Type    Measurement                       Description\n",
    "\n",
    "    Elevation                               quantitative    meters                       Elevation in meters\n",
    "    Aspect                                  quantitative    azimuth                      Aspect in degrees azimuth\n",
    "    Slope                                   quantitative    degrees                      Slope in degrees\n",
    "    Horizontal_Distance_To_Hydrology        quantitative    meters                       Horz Dist to nearest surface water features\n",
    "    Vertical_Distance_To_Hydrology          quantitative    meters                       Vert Dist to nearest surface water features\n",
    "    Horizontal_Distance_To_Roadways         quantitative    meters                       Horz Dist to nearest roadway\n",
    "    Hillshade_9am                           quantitative    0 to 255 index               Hillshade index at 9am, summer solstice\n",
    "    Hillshade_Noon                          quantitative    0 to 255 index               Hillshade index at noon, summer soltice\n",
    "    Hillshade_3pm                           quantitative    0 to 255 index               Hillshade index at 3pm, summer solstice\n",
    "    Horizontal_Distance_To_Fire_Points      quantitative    meters                       Horz Dist to nearest wildfire ignition points\n",
    "    Wilderness_Area (4 binary columns)      qualitative     0 (absence) or 1 (presence)  Wilderness area designation\n",
    "    Soil_Type (40 binary columns)           qualitative     0 (absence) or 1 (presence)  Soil Type designation\n",
    "    Cover_Type (7 types)                    integer         1 to 7                       Forest Cover Type designation\n",
    "\n",
    "\n",
    "Code Designations:\n",
    "\n",
    "    Wilderness Areas:   1 -- Rawah Wilderness Area\n",
    "                        2 -- Neota Wilderness Area\n",
    "                        3 -- Comanche Peak Wilderness Area\n",
    "                        4 -- Cache la Poudre Wilderness Area\n",
    "\n",
    "Soil Types:             1 to 40 - based on the USFS Ecological\n",
    "                        Landtype Units (ELUs) for this study area:\n",
    "\n",
    "\n",
    "      Forest Cover Type Classes:\t1 -- Spruce/Fir\n",
    "                                    2 -- Lodgepole Pine\n",
    "                                    3 -- Ponderosa Pine\n",
    "                                    4 -- Cottonwood/Willow\n",
    "                                    5 -- Aspen\n",
    "                                    6 -- Douglas-fir\n",
    "                                    7 -- Krummholz\n",
    "\n",
    "\n",
    "2.  Basic Summary Statistics for quantitative variables only\n",
    "\t(whole dataset -- thanks to Phil Rennert for the summary values):\n",
    "\n",
    "            Name                                    Units             Mean   Std Dev\n",
    "            Elevation                               meters          2959.36  279.98\n",
    "            Aspect                                  azimuth          155.65  111.91\n",
    "            Slope                                   degrees           14.10    7.49\n",
    "            Horizontal_Distance_To_Hydrology        meters           269.43  212.55\n",
    "            Vertical_Distance_To_Hydrology          meters            46.42   58.30\n",
    "            Horizontal_Distance_To_Roadways         meters          2350.15 1559.25\n",
    "            Hillshade_9am                           0 to 255 index   212.15   26.77\n",
    "            Hillshade_Noon                          0 to 255 index   223.32   19.77\n",
    "            Hillshade_3pm                           0 to 255 index   142.53   38.27\n",
    "            Horizontal_Distance_To_Fire_Points      meters          1980.29 1324.19\n",
    "\n",
    "\n",
    "3.\tMissing Attribute Values:  None.\n",
    "\n",
    "\n",
    "4.\tClass distribution:\n",
    "\n",
    "           Number of records of Spruce-Fir:                211840 \n",
    "           Number of records of Lodgepole Pine:            283301 \n",
    "           Number of records of Ponderosa Pine:             35754 \n",
    "           Number of records of Cottonwood/Willow:           2747\n",
    "           Number of records of Aspen:                       9493 \n",
    "           Number of records of Douglas-fir:                17367 \n",
    "           Number of records of Krummholz:                  20510  \n",
    "           Number of records of other:                          0  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a47e565",
   "metadata": {},
   "source": [
    "<a name=\"libraries\"></a>\n",
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1df99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score, confusion_matrix, classification_report, mean_squared_error, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c29900",
   "metadata": {},
   "source": [
    "<a name=\"clean\"></a>\n",
    "## Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1983be3",
   "metadata": {},
   "source": [
    "We have loaded the \"Covertype\" dataset and defined the column names, including binary column names generated based on their positions. Then, we have grouped the soil type columns into a single column by selecting the maximum value column index using idxmax(), creating the resulting column \"Soil type code\". And in the same way, we grouped the wilderness area columns into a single column by selecting the maximum value column index, in the column \"Wilderness area code\".\n",
    "\n",
    "Finally,we created a new column named \"Wilderness area description\", which contains the description of codes for Soil type and wilderness areas.The column \"soil type description\" contains the corresponding description of the soil type code. And we rearranged the order of columns to place \"Cover_Type_code\" at the end. We also created a new column called \"cover type description\" containing the corresponding description of the cover type code.\n",
    "\n",
    "These operations involve data manipulation, column renaming, and the addition of descriptive columns to enhance the interpretability of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e434b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./dataset/covtype_data.csv\")\n",
    "\n",
    "# Define column names\n",
    "col_names = ['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology ',\n",
    "             'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "             'Horizontal_Distance_To_Fire_Points']\n",
    "\n",
    "# Generate names for binary columns based on their position\n",
    "binary_col_names = [i+1 for i in range(4)]\n",
    "binary_col_names += [i+1 for i in range(40)]\n",
    "\n",
    "# Append the binary column names to the list of column names\n",
    "col_names += binary_col_names\n",
    "\n",
    "# Append the target variable name to the list of column names\n",
    "col_names.append('Cover_Type_code')\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "df.columns = col_names\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf08c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping the soil type columns into 1 column\n",
    "df['Soil type code'] = df.iloc[:, 14:54].idxmax(axis=1)\n",
    "df = pd.concat([df.iloc[:, :14], df.iloc[:, 54:]], axis=1)\n",
    "\n",
    "#Grouping the Wilderness Areas columns into 1 column\n",
    "df['Wilderness area code'] = df.iloc[:, 10:14].idxmax(axis=1)\n",
    "df = pd.concat([df.iloc[:, :10], df.iloc[:, 14:]], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb624cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()\n",
    "#add a column with the description of codes for Soil type and wilderness areas\n",
    "Wilderness_areas_list=['Rawah Wilderness Area','Neota Wilderness Area','Comanche Peak Wilderness Area' ,'Cache la Poudre Wilderness Area']\n",
    "df1['Wilderness area description']=[Wilderness_areas_list[col-1] for col in df1['Wilderness area code']]\n",
    "\n",
    "list_of_soil_type=pd.read_csv(\"./dataset/list_of_soil_types.csv\")\n",
    "list_of_soil_type=list(list_of_soil_type)\n",
    "df1['soil type description']=[list_of_soil_type[col-1] for col in df1['Soil type code']]\n",
    "\n",
    "new_order = [col for col in df1.columns if col != 'Cover_Type_code'] + ['Cover_Type_code']\n",
    "df1 = df1[new_order]\n",
    "\n",
    "cover_type_list=['Spruce/Fir','Lodgepole Pine','Ponderosa Pine','Cottonwood/Willow','Aspen','Douglas-fir','Krummholz']\n",
    "df1['cover type description']=[cover_type_list[col-1] for col in df1['Cover_Type_code']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134a026e",
   "metadata": {},
   "source": [
    "<a name=\"eda\"></a>\n",
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a1eb31",
   "metadata": {},
   "source": [
    "The Exploratory Data Analysis (EDA) is a critical step in data analysis process that aims to summarize, visualize, and understand the underlying structure and patterns in a dataset. This helps in identifying trends, anomalies, and potential relationships among variables, which can ultimately lead to the development of appropriate statistical models and hypothesis testing.\n",
    "\n",
    "In our project, the dataset consists of binary columns representing wilderness areas and soil types, as well as the target variable, which is the forest cover type.\n",
    "\n",
    "To perform the EDA, the team started by defining column names and generating names for binary columns based on their position. These binary column names were then appended to the list of column names, along with the target variable (cover type). After renaming the columns in the dataframe, the team proceeded to analyze the numerical columns by printing summary statistics. \n",
    "\n",
    "This process helped to gain a better understanding of the central tendencies and dispersion within the data.\n",
    "\n",
    "To further explore the distribution of the target variable, we printed the count of each target value and created a histogram. This provided insights into the frequency of different forest cover types and highlighted potential imbalances in the dataset. By examining the dataset in this manner, our group was able to identify trends, patterns, and potential relationships among variables, which will help us selecting the appropriate techniques for modeling and prediction in the next stages of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a7673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary statistics of the numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94874ea",
   "metadata": {},
   "source": [
    "The \"count\", \"mean\", \"min\", and \"max\" rows are self-explanatory. The \"std\" row shows the standard deviation (which measures how dispersed the values are). The 25%, 50%, and 75% rows show the corresponding percentiles: a percentile indicates the value below which a given percentage of observations in a group of observations falls.\n",
    "\n",
    "Another quick way to get a feel of the type of data you are dealing with is to plot a histogram for each numerical attribute. A histogram shows the number of instances (on the vertical axis) that have a given value range (on the horizontal axis). You can either plot this one attribute at a time, or you can call the hist() method on the whole dataset, and it will plot a histogram for each numerical attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83cbd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.hist(bins=40, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d061d3",
   "metadata": {},
   "source": [
    "The histogram plot shows the distribution of all the numeric columns in the dataset.\n",
    "- The \"Elevation\" column seems to be roughly normally distributed, with the majority of values falling in the range of 2500-3300.\n",
    "- The \"Aspect\" column appears to have a roughly uniform distribution, with no clear trend or peak in the data.\n",
    "- The \"Slope\" column has a right-skewed distribution, indicating that the majority of slopes are relatively gentle, with a long tail of steeper slopes.\n",
    "- The \"Horizontal_Distance_To_Hydrology\" and \"Vertical_Distance_To_Hydrology\" columns both have a strong peak at 0, indicating that many of the observations have no distance to hydrology.\n",
    "- The \"Horizontal_Distance_To_Roadways\" column is roughly normally distributed, with a peak around 0-500.\n",
    "- The \"Hillshade\" columns (9am, Noon, and 3pm) are all roughly normally distributed, with peaks around 200-255.\n",
    "- The \"Horizontal_Distance_To_Fire_Points\" column is right-skewed, indicating that the majority of observations have relatively short distances to fire points.\n",
    "\n",
    "Now we divide the data to train and test sets to explore the train set only.\n",
    "\n",
    "We are doing this in order to avoid the \"data snooping bias\": the bias that can come up when analyzing data that has been manipulated or transformed based on information that would not have been available at the time of the analysis (being so early in the analysis yet). It could lead us into selecting a particular kind of machine learning model based on too optimist observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b879f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(df1, test_size=0.2, random_state=42)\n",
    "train = train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006aee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = train.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e381567",
   "metadata": {},
   "source": [
    "#### Distribution of cover type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac1c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the distribution'cover type description' column\n",
    "plt.figure(figsize=(10, 8))\n",
    "percentage = df1['Cover_Type_code'].value_counts(normalize=True) * 100\n",
    "# create a bar plot of the percentages of each unique value in the 'cover type description' column\n",
    "percentage.plot(kind='bar')\n",
    "# display the plot\n",
    "plt.xlabel('Cover Type')\n",
    "plt.ylabel('Percentage')\n",
    "\n",
    "# add percentage labels to the bars\n",
    "for index, value in enumerate(percentage):\n",
    "    code = percentage.index[index]\n",
    "    desc = df1[df1['Cover_Type_code'] == code]['cover type description'].unique()[0]\n",
    "    plt.text(index, value + 1, f'{code} - {desc}\\n{round(value, 2)}%', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff05a0",
   "metadata": {},
   "source": [
    "#### Distribution of elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb484bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a density plot of the 'elevation' column\n",
    "sns.kdeplot(df1['Elevation'], shade=True)\n",
    "plt.xlabel('Elevation')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of Elevation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdc2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Cover_Type_code', y='Elevation', data=df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90fbcfc",
   "metadata": {},
   "source": [
    "From the plot, we can see that Cover_Type_code 1, 2, and 7 have relatively higher median elevations than the other categories. In contrast, Cover_Type_code 3 and 4 have lower median elevations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe004d",
   "metadata": {},
   "source": [
    "#### Distribution of wilderness area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af22ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the distribution'cover type description' column\n",
    "plt.figure(figsize=(10, 8))\n",
    "percentage = df1['Soil type code'].value_counts(normalize=True) * 100\n",
    "# create a bar plot of the percentages of each unique value in the 'Wilderness area description' column\n",
    "percentage.plot(kind='bar')\n",
    "# display the plot\n",
    "plt.xlabel('Wilderness area')\n",
    "plt.ylabel('percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c15e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the distribution'cover type description' column\n",
    "plt.figure(figsize=(10, 8))\n",
    "percentage = df1['Wilderness area description'].value_counts(normalize=True) * 100\n",
    "# create a bar plot of the percentages of each unique value in the 'Wilderness area description' column\n",
    "percentage.plot(kind='bar')\n",
    "# display the plot\n",
    "plt.xlabel('Wilderness area')\n",
    "plt.ylabel('percentage')\n",
    "\n",
    "# add percentage labels to the bars\n",
    "for index, value in enumerate(percentage):\n",
    "    plt.text(index, value + 1, str(round(value, 2)) + '%', ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178f57d",
   "metadata": {},
   "source": [
    "# Models:\n",
    "\n",
    "In order to predict forest cover types based on cartographic variables, our team has selected three machine learning models, which are well-suited to this dataset: classification, decision tree, and clustering.\n",
    "\n",
    "**Decision Tree:** decision trees are a benchmark for our analysis, they can handle both numerical and categorical features, like the binary columns for wilderness areas and soil types. These models are easily interpretable and can capture non-linear relationships between features and the target variable. They are capable of selecting the most relevant features for prediction, which can help improve overall model performance. On the other side, it is common for them to overfit, that is why, for the sake of completeness, this is not the only method we employ.\n",
    "\n",
    "**Logistic Regression:** \n",
    "\n",
    "**Neural Network:**\n",
    "\n",
    "**GBoosting:**\n",
    "\n",
    "**Random Forests:**\n",
    "\n",
    "By employing these six machine learning models, we aim to harness their unique strengths and capabilities in order to accurately predict forest cover types for our dataset. Through rigorous model evaluation and comparison, we will select the best-performing model that achieves the highest prediction accuracy and generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67560610",
   "metadata": {},
   "source": [
    "### Definining Features and Target Variables for our models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bdff45",
   "metadata": {},
   "source": [
    "In ML, having a large amount of data is crucial for training models that can accurately make predictions. However, processing large datasets can be computationally expensive and time-consuming, especially when running multiple models. Therefore, using a smaller subset of the data can help to reduce the time and computational resources required for training and testing models.\n",
    "\n",
    "In this case, using a subset of 100,000 instances allows us to build and test multiple models quickly without sacrificing too much data. By randomly selecting a subset, we can ensure that the sample is representative of the larger dataset while reducing the overall size of the data. This approach can be particularly useful when dealing with big data, where even a small subset can be sufficiently representative of the entire dataset.\n",
    "\n",
    "Moreover, using a smaller subset can also help to avoid overfitting, which occurs when a model is trained too closely on the training data and fails to generalize to new data. By using a smaller subset, we can limit the complexity of the models we build, making them less likely to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a random subset of the data (because the dataset is too large)\n",
    "subset_size = 100000 # Change this value to the desired subset size\n",
    "random_indices = np.random.choice(df.index, subset_size, replace=False)\n",
    "df_subset = df.loc[random_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022dfce5",
   "metadata": {},
   "source": [
    "ADD EXPLANATION THAT DISTRIBUTION HAS NOT BEEN AFFECTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34591632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the distribution'cover type description' column\n",
    "plt.figure(figsize=(10, 8))\n",
    "percentage = df1['Cover_Type_code'].value_counts(normalize=True) * 100\n",
    "# create a bar plot of the percentages of each unique value in the 'cover type description' column\n",
    "percentage.plot(kind='bar')\n",
    "# display the plot\n",
    "plt.xlabel('Cover Type')\n",
    "plt.ylabel('Percentage')\n",
    "\n",
    "# add percentage labels to the bars\n",
    "for index, value in enumerate(percentage):\n",
    "    code = percentage.index[index]\n",
    "    desc = df1[df1['Cover_Type_code'] == code]['cover type description'].unique()[0]\n",
    "    plt.text(index, value + 1, f'{code} - {desc}\\n{round(value, 2)}%', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of the distribution'cover type description' column\n",
    "plt.figure(figsize=(10, 8))\n",
    "percentage = df_subset['Cover_Type_code'].value_counts(normalize=True) * 100\n",
    "# create a bar plot of the percentages of each unique value in the 'cover type description' column\n",
    "percentage.plot(kind='bar')\n",
    "# display the plot\n",
    "plt.xlabel('Cover Type')\n",
    "plt.ylabel('Percentage')\n",
    "\n",
    "# add percentage labels to the bars\n",
    "for index, value in enumerate(percentage):\n",
    "    code = percentage.index[index]\n",
    "    #desc = df_subset[df_subset['Cover_Type_code'] == code]['cover type description'].unique()[0]\n",
    "    plt.text(index, value + 1, f'{code} - {desc}\\n{round(value, 2)}%', ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49422dd",
   "metadata": {},
   "source": [
    "The input data consists of five features: \"Wilderness area code\", \"Elevation\", \"Horizontal_Distance_To_Roadways\", \"Horizontal_Distance_To_Fire_Points\", and \"Soil type code\". These features are used to predict the cover type, which is a categorical variable represented by the \"Cover_Type_code\" column.\n",
    "\n",
    "**EXPLAIN WHY WE CHOSE THOSE FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5557bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "\n",
    "#X = df_subset.drop(\"Cover_Type_code\", axis=1)\n",
    "X = df_subset[[\"Wilderness area code\", \"Elevation\", \"Soil type code\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Slope',\"Hillshade_Noon\",\"Hillshade_3pm\"]]\n",
    "y = df_subset[\"Cover_Type_code\"]\n",
    "#X = df[[\"Wilderness area code\", \"Elevation\", 'Horizontal_Distance_To_Roadways', 'Horizontal_Distance_To_Fire_Points', 'Soil type code']]\n",
    "#y = df[\"Cover_Type_code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c90404",
   "metadata": {},
   "source": [
    "### Splitting the dataset into training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5669a7",
   "metadata": {},
   "source": [
    "Dividing the dataset into training and testing sets is an essential step in machine learning to evaluate the performance of the model. In this case, the dataset is split into 80% training data and 20% testing data.\n",
    "\n",
    "The reason for using an 80/20 split is that it strikes a balance between having enough data to train the model while still having a sufficient amount of data to evaluate the model's performance. The training data is used to fit the model parameters, while the testing data is used to evaluate how well the model generalizes to new, unseen data.\n",
    "\n",
    "If we use too little data for training, the model may not learn the underlying patterns in the data correctly, resulting in poor performance. Conversely, if we use too much data for training, the model may overfit, which means it will perform well on the training data but poorly on the testing data.\n",
    "\n",
    "The 80/20 split is a common default choice for many machine learning applications, but it can be adjusted based on the size and complexity of the dataset and the problem being solved. For example, if the dataset is small, we may need to use a higher percentage of the data for training, such as a 70/30 split. In contrast, if the dataset is large, we may use a smaller percentage for training, such as a 90/10 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cef542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dfset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f33f9df",
   "metadata": {},
   "source": [
    "### Why accuracy evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c4b87",
   "metadata": {},
   "source": [
    "The research on environmental monitoring and forest cover analysis necessitates careful consideration of evaluation metrics to assess machine learning model performance. In this study, the utilization of \"accuracy\" and \"balanced accuracy\" as evaluation parameters proves highly motivating for several reasons.\n",
    "\n",
    "Accuracy, a widely embraced metric in machine learning, gauges the proportion of correctly classified instances among the total instances in the dataset. Aiming for high accuracy entails the development of models that effectively predict forest cover types based on provided cartographic variables. \n",
    "As an evaluation parameter, accuracy, motivates the focus on minimizing misclassifications, recognizing that even small errors in classifying forest cover types can have consequences. Striving for high accuracy ensures the provision of effective and reliable information for forest management decisions, wildfire prevention strategies, conservation planning, and climate change adaptation.\n",
    "\n",
    "Even though accuracy is crucial, it may not be the most suitable choice when dealing with imbalanced datasets, such as the one we chose for our project, which actually arise commonly in real-world datasets. We have imbalanced datasets when the distribution of different forest cover types is uneven. **Balanced accuracy** addresses this issue by considering the imbalances in class distribution. It provides a more dependable measure of classification performance by calculating the accuracy for each class individually and then determining the average. Balanced accuracy prevents bias toward the majority class, ensuring that vital information related to less prevalent forest cover types is not overlooked.\n",
    "\n",
    "### Where there other evaluation parameters?\n",
    "\n",
    "Precision, recall, F1 score, confusion matrix, and AUC-ROC are valuable evaluation metrics that provide a comprehensive view of a model's performance. However, in the context of our research on environmental monitoring and forest cover analysis in Colorado, we chose not to utilize them for the following reasons:\n",
    "\n",
    "1. **Precision:** in our case, precision may not be the most suitable metric because the focus is not solely on identifying positive instances, but rather on accurately classifying different forest cover types. Precision alone does not provide sufficient information.\n",
    "\n",
    "2. **Recall:** while recall is important in scenarios where identifying all positive instances is critical, such as in medical diagnosis, our research primarily focuses on understanding the state of the forest ecosystem and identifying potential threats to its health. \n",
    "\n",
    "3. **Confusion Matrix:** is valuable for understanding the types of errors a model is making, but the confusion matrix alone does not provide a single aggregated metric that represents overall model performance, which is important for making informed decisions in environmental monitoring and forest management.\n",
    "\n",
    "4. **AUC-ROC:** in our paper, where the primary focus is on accurate forest cover type classification rather than binary classification, the AUC-ROC may not provide a suitable evaluation metric. \n",
    "\n",
    "In conclusion, the adoption of accuracy and balanced accuracy as evaluation parameters in this research emphasizes the development of reliable models for forest cover type classification. The aim is always to obtain high accuracy that ensures our models contribute to informed decision-making, promote an impact on forest management, conservation efforts, and the overall well-being of Colorado's forests and ecosystems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56c3cd",
   "metadata": {},
   "source": [
    "<a name=\"model1\"></a>\n",
    "\n",
    "## 1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X.columns)\n",
    "\n",
    "# Split the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a decision tree classifier with a range of depths to search\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    \"max_depth\": range(1, 4),\n",
    "    \"min_samples_split\": range(2, 4, 2),\n",
    "    \"min_samples_leaf\": range(1, 4, 2)\n",
    "}\n",
    "\n",
    "#decision_tree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "#grid_search = GridSearchCV(clf, param_grid, scoring=\"accuracy\", cv=5, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "#best_clf = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the testing dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Evaluate the balanced accuracy of the model\n",
    "b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy: {b_accuracy:.2f}\")\n",
    "\n",
    "# Calculate the confusion matrix of the model\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "class_names = [0, 1, 2, 3, 4, 5, 6]  # Name of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(30, 20))\n",
    "plot_tree(clf, feature_names=features, class_names=['0', '1', '2', '3', '4', '5', '6'], filled=True)\n",
    "plt.show()\n",
    "\n",
    "# Print the evaluation matrix\n",
    "target_names = ['0', '1', '2', '3', '4', '5', '6']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2227c20b",
   "metadata": {},
   "source": [
    "For now we will remove max deph to improve the aacuracy of our decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16146dd",
   "metadata": {},
   "source": [
    "<a name=\"model2\"></a>\n",
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01950c5a",
   "metadata": {},
   "source": [
    "We decided to use a logistic regression model for this task due to its simplicity, interpretability, and effectiveness in many classification problems. We performed feature scaling with StandardScaler by removing the mean and scaling to unit variance to standardize the input features due to scaling sensitivity. This way, we ensure that all features have the same scale, which helps the logistic regression algorithm converge faster and provide better performance.\n",
    "\n",
    "After feature scaling, we proceeded to train the logistic regression model using the LogisticRegression class from the scikit-learn library. We set the maximum number of iterations to 1000 to give the optimization algorithm enough iterations to converge to an optimal solution. In some cases, logistic regression models may require more iterations to find the optimal weights, especially when dealing with complex datasets or large feature spaces. By setting a higher number of iterations, we can ensure that the optimization algorithm has sufficient opportunities to find the best solution within the given constraint.\n",
    "\n",
    "We used the 'lbfgs' solver as it is a popular optimization algorithm for logistic regression. This algorithm is an efficient optimization technique that approximates the BFGS algorithm using a limited amount of memory. This solver is suitable for large-scale problems and can handle a wide range of data sizes and complexities. Additionally, the 'lbfgs' solver works well with L2 regularization, which is commonly used in logistic regression to prevent overfitting and improve generalization.\n",
    "\n",
    "We specified the multi_class parameter as 'multinomial' to handle the multi-class classification problem. In a multi-class classification problem, there are more than two classes to predict. The 'multinomial' option enables the logistic regression model to handle such problems by using the softmax function to estimate probabilities for each class. The softmax function is a generalization of the logistic function that can handle multiple classes, converting the model's output into class probabilities. By using the 'multinomial' option, we ensure that our logistic regression model is well-suited to handle the multi-class nature of the cover type classification problem.\n",
    "\n",
    "Once the logistic regression model was trained, we made predictions on the test set and evaluated its performance using accuracy as the performance metric. Accuracy is a common metric used to measure the proportion of correct predictions made by the model out of the total number of predictions. We also performed cross-validation to assess the model's generalization capability. Cross-validation is a technique used to estimate the performance of a model on unseen data by splitting the training data into multiple subsets, training the model on each subset, and evaluating the performance on the remaining data. In our case, we used 5-fold cross-validation, which means that the training data was split into five equal parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d475cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy: {b_accuracy:.2f}\")\n",
    "\n",
    "# Perform cross-validation\n",
    "#cv_scores = cross_val_score(logreg, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "#print(f\"Cross-Validation Accuracy: {np.mean(cv_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db996745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(logreg, X_test_scaled, y_test, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84da0255",
   "metadata": {},
   "source": [
    "ADD CONFUSION MATRIX EXPLANATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817e671",
   "metadata": {},
   "source": [
    "We also performed hyperparameter tuning to find the best parameters for our model. However, this didn't improve the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb39b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline for data scaling and logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000, multi_class='multinomial'))\n",
    "])\n",
    "\n",
    "# Set up a grid of hyperparameters for tuning\n",
    "param_grid = {\n",
    "    'logreg__solver': ['lbfgs', 'sag', 'saga'],\n",
    "    'logreg__C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and evaluate it on the testing set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(best_model)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df034c4c",
   "metadata": {},
   "source": [
    "We chose logistic regression with feature scaling for this cover type classification task due to its simplicity, interpretability, and effectiveness for such problems. We also evaluated the model using accuracy and cross-validation to ensure its generalizability to unseen data.\n",
    "\n",
    "While logistic regression is a simple and interpretable model often used for classification problems, it may not always be the best choice depending on the complexity and nature of the problem. In our case, the reported accuracy of 0.71 indicates that the model's performance is not optimal compared to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab9d6c",
   "metadata": {},
   "source": [
    "<a name=\"model3\"></a>\n",
    "# 3. Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d039d4",
   "metadata": {},
   "source": [
    "We used a simple feedforward neural network (also known as a multilayer perceptron) for predicting cover types, which is a classification problem. The model is implemented using the Keras library. \n",
    "\n",
    "We used the StandardScaler from scikit-learn to normalize the features. This is important as it helps to ensure that all features have a similar scale, which can improve the performance of the model.\n",
    "\n",
    "\n",
    "We ensured that the target variable is integer-encoded and starts from 0, which is required when using 'sparse_categorical_crossentropy' as the loss function. The model consists of an input layer, two hidden layers with 10 neurons each, and an output layer. The activation functions used are ReLU (rectified linear unit) for the hidden layers and softmax for the output layer. Softmax is used for the output layer because it is suitable for multi-class classification problems, as it converts the output into probabilities that sum to 1.\n",
    "\n",
    "The model is compiled using 'sparse_categorical_crossentropy' as the loss function and the 'adam' optimizer. The 'sparse_categorical_crossentropy' loss function is suitable for multi-class classification problems with integer-encoded labels. We trained the model for 50 epochs with a batch size of 10.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "473d794e",
   "metadata": {},
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Ensure the target variable is integer-encoded (starting from 0)\n",
    "y_train = y_train.astype(int) - 1\n",
    "y_test = y_test.astype(int) - 1\n",
    "\n",
    "# Define the model\n",
    "num_classes = len(np.unique(y_train))\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Changed activation to 'softmax' and the number of units to match the number of classes\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # Changed loss to 'sparse_categorical_crossentropy'\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_r = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_r)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Evaluate the balanced accuracy of the model\n",
    "b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy: {b_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a09104",
   "metadata": {},
   "source": [
    "CAN ONLY BE RUN ON GOOGLE COLAB\n",
    "TAKES 1O MIN TO RUN AND GIVES:\n",
    "\n",
    "ACCURACY OF **0.73965**\n",
    "\n",
    "BALANCE ACCURACY OF: **...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de9ea30",
   "metadata": {},
   "source": [
    "The achieved accuracy of 0.73 might not be optimal for some applications, and other models might perform better. Some reasons to consider other models include that the chosen model is relatively simple and may not capture the complexity of the relationship between the features and the target variable.\n",
    "\n",
    "Moreover, the number of layers, neurons, and activation functions were selected arbitrarily, and a more systematic approach (e.g., using a grid search or randomized search) might lead to better model configurations.\n",
    "\n",
    "Other models, such as decision trees, random forests, support vector machines, or gradient boosting machines, might have better performance on this particular problem. Ensemble methods, which combine multiple models, can also lead to improved accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de29ea",
   "metadata": {},
   "source": [
    "<a name=\"model4\"></a>\n",
    "# 4. Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018aed98",
   "metadata": {},
   "source": [
    "The code is using the Random Forest Classifier algorithm to classify the cover type of a forest based on a number of environmental variables such as elevation, slope, and soil type. However, the dataset may contain irrelevant or redundant features that could negatively impact the accuracy of the model, and also increase the risk of overfitting\n",
    "\n",
    "To avoid overfitting, it's important to identify and remove any unnecessary features that do not contribute significantly to the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82b9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Random Forest : \n",
    "\n",
    "#try performing feature selection to identify and remove any unnecessary features .\n",
    "#This improves the performance of the model and reduce overfitting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Perform feature selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Create a random forest classifier with 10 trees\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Evaluate the balanced accuracy of the model\n",
    "b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy: {b_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af777f5f",
   "metadata": {},
   "source": [
    "<a name=\"model5\"></a>\n",
    "# 5. XG Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Ensure the target variable is integer-encoded (starting from 0)\n",
    "y_train = y_train + 1\n",
    "y_test = y_test + 1\n",
    "\n",
    "# Train an  XGBoosting model\n",
    "gb_model = xgb.XGBClassifier(max_depth=3, n_estimators=100, learning_rate=0.1)\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = gb_model.predict(X_test)\n",
    "# Evaluate the model\n",
    "accuracy_gb = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy (XGBOOST): {accuracy_gb:.2f}\")\n",
    "\n",
    "# Evaluate the balanced accuracy of the model\n",
    "b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy: {b_accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(gb_model, X_test, y_test, cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix (XGboost)\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "report_gb = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report (Gradient Boosting):\\n\", report_gb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d75ea2",
   "metadata": {},
   "source": [
    "<a name=\"model6\"></a>\n",
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c4754",
   "metadata": {},
   "source": [
    "An ensemble model combines multiple individual models to improve the overall performance. One common ensemble technique is the Voting Classifier, which takes the majority vote of different classifiers to make the final prediction. Here's a Voting Classifier using scikit-learn with a Random Forest, a Support Vector Machine, and a Gradient Boosting Classifier.\n",
    "\n",
    "In this example, we create a Voting Classifier that combines a Random Forest, a Support Vector Machine (with a radial kernel), and a Gradient Boosting Classifier. \n",
    "\n",
    "The voting parameter is set to 'soft', which means that the classifier will predict the class label based on the argmax of the class probabilities, calculated as the average of the predicted probabilities of the individual classifiers.\n",
    "\n",
    "It is possible to experiment with different combinations of classifiers and their hyperparameters to find the best performing ensemble for your problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "229e6dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8136\n"
     ]
    }
   ],
   "source": [
    "# Create the individual classifiers\n",
    "clf1 = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "clf2 = make_pipeline(StandardScaler(), SVC(kernel='rbf', probability=True, random_state=42))\n",
    "clf3 = GradientBoostingClassifier(n_estimators=50, random_state=42, n_iter_no_change=5, tol=0.01)\n",
    "\n",
    "# Create the ensemble model (Voting Classifier)\n",
    "eclf = VotingClassifier(estimators=[('rf', clf1), ('svc', clf2), ('gb', clf3)], voting='soft')\n",
    "\n",
    "# Train the ensemble model\n",
    "eclf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = eclf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae14c2",
   "metadata": {},
   "source": [
    "To optimize the model we can perform hyperparameter tuning to find the best parameters for the model. We used Grid Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dfc65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the individual classifiers with placeholder hyperparameters\n",
    "clf1 = RandomForestClassifier(random_state=42)\n",
    "clf2 = make_pipeline(StandardScaler(), SVC(kernel='linear', probability=True, random_state=42))\n",
    "clf3 = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Create the ensemble model (Voting Classifier)\n",
    "eclf = VotingClassifier(estimators=[('rf', clf1), ('svc', clf2), ('gb', clf3)], voting='soft')\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'svc__svc__C': [0.1, 1, 10],\n",
    "    'gb__n_estimators': [50, 100, 200],\n",
    "    'gb__learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", grid.best_params_)\n",
    "\n",
    "# Make predictions on the test set using the best ensemble model found\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c053ce39",
   "metadata": {},
   "source": [
    "<a name=\"compare\"></a>\n",
    "## Model Comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4586c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "414332df",
   "metadata": {},
   "source": [
    "<a name=\"best\"></a>\n",
    "## Best Model Selection and Improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d173998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Random Forest : \n",
    "\n",
    "#try performing feature selection to identify and remove any unnecessary features .\n",
    "#This improves the performance of the model and reduce overfitting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Perform feature selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Create a random forest classifier with 10 trees\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "# Create a feature selection object\n",
    "selector = SelectFromModel(rfc)\n",
    "\n",
    "# Fit the selector to the training data\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "# Transform the training and testing data to only include the selected features\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Fit the model to the training data using only the selected features\n",
    "rfc_selected = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the testing data using only the selected features\n",
    "y_pred_selected = rfc_selected.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy of the model using only the selected features\n",
    "accuracy_selected = accuracy_score(y_test, y_pred_selected)\n",
    "\n",
    "print(\"Accuracy (with feature selection):\", accuracy_selected)\n",
    "\n",
    "# Fit the selector to the training data\n",
    "selector.fit(X_train, y_train)\n",
    "selected_features = X_train.columns[selector.get_support()]\n",
    "print(\"Selected features:\", list(selected_features))\n",
    "\n",
    "rfc_selected.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77ba77f",
   "metadata": {},
   "source": [
    "<a name=\"conclusion\"></a>\n",
    "## Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ddd1ce",
   "metadata": {},
   "source": [
    "In conclusion, our research paper on environmental monitoring using machine learning models has potential to make a feasible impact on forest management and conservation efforts in the Roosevelt National Forest and its surroundings, and in general the State of Colorado and Wyoming. By analyzing the cartographic variables and forest cover type data, the selected machine learning models, including Decision Tree, Logistic Regression, Neural Network, GBoosting, and Random Forests, allowed us to accurately predict forest cover types based on the provided dataset. \n",
    "\n",
    "**The ensemble model, created using a Voting Classifier, demonstrated an accuracy of 81.26% on the test set, indicating its effectiveness in classifying forest cover types.** Also, to optimize the model, we performed hyperparameter tuning using Grid Search, resulting in the identification of the best hyperparameters for each individual classifier within the ensemble model.\n",
    "\n",
    "Our research findings and the developed models can serve as a benchmark for managerial choices in forest management. The government can benefit from the insights provided by our research. Additionally, interested organizations operating in or near forested areas in Colorado can acquire and license our research findings as environmental consulting services. This would assist them in complying with wildfire prevention regulations, developing emergency response plans, and adhering to environmental laws and guidelines, ultimately promoting sustainable practices and safeguarding the long-term sustainability of Colorado's forests. \n",
    "\n",
    "In summary, our research on environmental monitoring using machine learning models, particularly the ensemble model developed through the Voting Classifier, along with the application of feature selection techniques, offers a reliable and efficient approach for predicting forest cover types and understanding the state of the forest ecosystem. These findings provide a foundation for better forest management and conservation practices, enabling informed decision-making."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e36f5ea",
   "metadata": {},
   "source": [
    "<a name=\"sources\"></a>\n",
    "## Sources\n",
    "\n",
    "Original Owners of Database: \n",
    "\n",
    "Remote Sensing and GIS Program \n",
    "\n",
    "Department of Forest Sciences\n",
    "\n",
    "College of Natural Resources\n",
    "\n",
    "Colorado State University \n",
    "\n",
    "Fort Collins, CO 80523 \n",
    "\n",
    "(contact Jock A. Blackard, jblackard@fs.fed.us or Dr. Denis J. Dean, denis.dean@utdallas.edu) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc46476",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
